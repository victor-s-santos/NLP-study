{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalando a Versão do Curso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy==2.2.3\n",
      "  Using cached spacy-2.2.3-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.2-cp38-cp38-manylinux1_x86_64.whl (118 kB)\n",
      "Requirement already satisfied: setuptools in /home/visus/anaconda3/lib/python3.8/site-packages (from spacy==2.2.3) (49.2.0.post20200714)\n",
      "Collecting blis<0.5.0,>=0.4.0\n",
      "  Using cached blis-0.4.1-cp38-cp38-manylinux1_x86_64.whl (3.7 MB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/visus/anaconda3/lib/python3.8/site-packages (from spacy==2.2.3) (1.18.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/visus/anaconda3/lib/python3.8/site-packages (from spacy==2.2.3) (2.24.0)\n",
      "Collecting plac<1.2.0,>=0.9.6\n",
      "  Using cached plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting wasabi<1.1.0,>=0.4.0\n",
      "  Using cached wasabi-0.7.1.tar.gz (22 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.3-cp38-cp38-manylinux1_x86_64.whl (33 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.2-cp38-cp38-manylinux1_x86_64.whl (19 kB)\n",
      "Collecting catalogue<1.1.0,>=0.0.7\n",
      "  Using cached catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Collecting thinc<7.4.0,>=7.3.0\n",
      "  Using cached thinc-7.3.1-cp38-cp38-manylinux1_x86_64.whl (2.2 MB)\n",
      "Collecting srsly<1.1.0,>=0.1.0\n",
      "  Using cached srsly-1.0.2-cp38-cp38-manylinux1_x86_64.whl (185 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/visus/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/visus/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/visus/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/visus/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (3.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/visus/anaconda3/lib/python3.8/site-packages (from thinc<7.4.0,>=7.3.0->spacy==2.2.3) (4.47.0)\n",
      "Building wheels for collected packages: wasabi\n",
      "  Building wheel for wasabi (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wasabi: filename=wasabi-0.7.1-py3-none-any.whl size=20834 sha256=a60da960b30aedd6dfdd870b492cf5dfda58672dd0e0a324c69087380cfa5d43\n",
      "  Stored in directory: /home/visus/.cache/pip/wheels/f2/d4/16/366223ea944794b7a8ff2194de44033ceef210e8d8bb76fe79\n",
      "Successfully built wasabi\n",
      "Installing collected packages: murmurhash, cymem, preshed, blis, plac, wasabi, catalogue, srsly, thinc, spacy\n",
      "Successfully installed blis-0.4.1 catalogue-1.0.0 cymem-2.0.3 murmurhash-1.0.2 plac-1.1.3 preshed-3.0.2 spacy-2.2.3 srsly-1.0.2 thinc-7.3.1 wasabi-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy==2.2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Download e instalação dos pacotes em Português:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pt_core_news_sm==2.2.5\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.2 MB 4.4 MB/s eta 0:00:01     |██████████████████████▊         | 15.1 MB 1.2 MB/s eta 0:00:06\n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /home/visus/anaconda3/lib/python3.8/site-packages (from pt_core_news_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/visus/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.7.1)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /home/visus/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/visus/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/visus/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/visus/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/visus/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /home/visus/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (49.2.0.post20200714)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/visus/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.18.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/visus/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.24.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/visus/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/visus/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/visus/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/visus/anaconda3/lib/python3.8/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.47.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/visus/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/visus/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/visus/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/visus/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
      "Building wheels for collected packages: pt-core-news-sm\n",
      "  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.2.5-py3-none-any.whl size=21186283 sha256=be42fb7908818b683874b871e180a3eeeac93411dcb2399793c215d29214e0ca\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-5oi26ll6/wheels/81/c3/05/0d8e031490707ac9e6409c6fd9d755f6359e25ed187794a36c\n",
      "Successfully built pt-core-news-sm\n",
      "Installing collected packages: pt-core-news-sm\n",
      "Successfully installed pt-core-news-sm-2.2.5\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('pt_core_news_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/home/visus/anaconda3/lib/python3.8/site-packages/pt_core_news_sm -->\n",
      "/home/visus/anaconda3/lib/python3.8/site-packages/spacy/data/pt\n",
      "You can now load the model via spacy.load('pt')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mão na massa:\n",
    " * __Marcação POS:__\n",
    "- POS (part-of-speech) atribui para as palavras partes da fala, como substantivos, adjetivos, verbos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definindo o objeto de linguagem natural em lingua portuguesa\n",
    "nlp = spacy.load('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usando o objeto\n",
    "document1 = nlp('Python é 42.')\n",
    "document2 = nlp('Estudo da linguagem Python para processamento natural de linguagem.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python PROPN\n",
      "é VERB\n",
      "42 NUM\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "#trazendo o pos \n",
    "for word in document1:\n",
    "    print(word.text, word.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estudo NOUN\n",
      "da ADP\n",
      "linguagem NOUN\n",
      "Python PROPN\n",
      "para ADP\n",
      "processamento NOUN\n",
      "natural ADJ\n",
      "de ADP\n",
      "linguagem NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for word in document2:\n",
    "    print(word.text, word.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legenda dos atributos do objeto\n",
    "- lemma: raiz da palavra\n",
    "- pos: parte da fala\n",
    "- tag: informações morfológicas, como se o verbo está no passado\n",
    "- dep: dependência sintática\n",
    "- shape: formato (maiúsculo, minúsculo, dígitos)\n",
    "- alpha: se é alfabético\n",
    "- stop: se é stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavra:Estudo\n",
      " Raiz da palavra: Estudo\n",
      " Parte da fala: NOUN\n",
      " Morfologia: <np-idf>|N|M|S|@NPHR\n",
      " Dependência sintática: ROOT\n",
      " Formato: Xxxxx\n",
      " Numérico: True\n",
      " Stop Word: False\n",
      "\n",
      "Palavra:da\n",
      " Raiz da palavra: da\n",
      " Parte da fala: ADP\n",
      " Morfologia: ADP\n",
      " Dependência sintática: case\n",
      " Formato: xx\n",
      " Numérico: True\n",
      " Stop Word: True\n",
      "\n",
      "Palavra:linguagem\n",
      " Raiz da palavra: linguagem\n",
      " Parte da fala: NOUN\n",
      " Morfologia: <np-idf>|N|F|S|@P<\n",
      " Dependência sintática: nmod\n",
      " Formato: xxxx\n",
      " Numérico: True\n",
      " Stop Word: False\n",
      "\n",
      "Palavra:Python\n",
      " Raiz da palavra: Python\n",
      " Parte da fala: PROPN\n",
      " Morfologia: PROP|F|S|@N<\n",
      " Dependência sintática: ROOT\n",
      " Formato: Xxxxx\n",
      " Numérico: True\n",
      " Stop Word: False\n",
      "\n",
      "Palavra:para\n",
      " Raiz da palavra: parir\n",
      " Parte da fala: ADP\n",
      " Morfologia: PRP|@<ADVL\n",
      " Dependência sintática: case\n",
      " Formato: xxxx\n",
      " Numérico: True\n",
      " Stop Word: True\n",
      "\n",
      "Palavra:processamento\n",
      " Raiz da palavra: processamento\n",
      " Parte da fala: NOUN\n",
      " Morfologia: <np-idf>|N|M|S|@P<\n",
      " Dependência sintática: nmod\n",
      " Formato: xxxx\n",
      " Numérico: True\n",
      " Stop Word: False\n",
      "\n",
      "Palavra:natural\n",
      " Raiz da palavra: natural\n",
      " Parte da fala: ADJ\n",
      " Morfologia: ADJ|M|S|@N<\n",
      " Dependência sintática: amod\n",
      " Formato: xxxx\n",
      " Numérico: True\n",
      " Stop Word: False\n",
      "\n",
      "Palavra:de\n",
      " Raiz da palavra: de\n",
      " Parte da fala: ADP\n",
      " Morfologia: PRP|@N<\n",
      " Dependência sintática: case\n",
      " Formato: xx\n",
      " Numérico: True\n",
      " Stop Word: True\n",
      "\n",
      "Palavra:linguagem\n",
      " Raiz da palavra: linguagem\n",
      " Parte da fala: NOUN\n",
      " Morfologia: <np-idf>|N|F|S|@P<\n",
      " Dependência sintática: nmod\n",
      " Formato: xxxx\n",
      " Numérico: True\n",
      " Stop Word: False\n",
      "\n",
      "Palavra:.\n",
      " Raiz da palavra: .\n",
      " Parte da fala: PUNCT\n",
      " Morfologia: PU|@PU\n",
      " Dependência sintática: punct\n",
      " Formato: .\n",
      " Numérico: False\n",
      " Stop Word: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in document2:\n",
    "    print(f'Palavra:{word}\\n', f'Raiz da palavra: {word.lemma_}\\n', f'Parte da fala: {word.pos_}\\n', \n",
    "          f'Morfologia: {word.tag_}\\n', f'Dependência sintática: {word.dep_}\\n', \n",
    "          f'Formato: {word.shape_}\\n', f'Numérico: {word.is_alpha}\\n', \n",
    "          f'Stop Word: {word.is_stop}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavra:Python\n",
      " Raiz da palavra: Python\n",
      " Parte da fala: PROPN\n",
      " Morfologia: PROP|M|S|@SUBJ>\n",
      " Dependência sintática: nsubj\n",
      " Formato: Xxxxx\n",
      " Numérico: True\n",
      " Stop Word: False\n",
      "\n",
      "Palavra:é\n",
      " Raiz da palavra: ser\n",
      " Parte da fala: VERB\n",
      " Morfologia: <mv>|V|PR|3S|IND|@FS-STA\n",
      " Dependência sintática: cop\n",
      " Formato: x\n",
      " Numérico: True\n",
      " Stop Word: True\n",
      "\n",
      "Palavra:42\n",
      " Raiz da palavra: 42\n",
      " Parte da fala: NUM\n",
      " Morfologia: <card>|NUM|M|P|@N<\n",
      " Dependência sintática: ROOT\n",
      " Formato: dd\n",
      " Numérico: False\n",
      " Stop Word: False\n",
      "\n",
      "Palavra:.\n",
      " Raiz da palavra: .\n",
      " Parte da fala: PUNCT\n",
      " Morfologia: PU|@PU\n",
      " Dependência sintática: punct\n",
      " Formato: .\n",
      " Numérico: False\n",
      " Stop Word: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in document1:\n",
    "    print(f'Palavra:{word}\\n', f'Raiz da palavra: {word.lemma_}\\n', f'Parte da fala: {word.pos_}\\n', \n",
    "          f'Morfologia: {word.tag_}\\n', f'Dependência sintática: {word.dep_}\\n', \n",
    "          f'Formato: {word.shape_}\\n', f'Numérico: {word.is_alpha}\\n', \n",
    "          f'Stop Word: {word.is_stop}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematização:\n",
    "- Lematização: \"Lema\" de uma palavra de acordo com seu significado no dicionário - palavra base (análise vocabular e morfológica)\n",
    "- OBS: Chama-se stemização(do nltk) a  simples extração do radical das palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Python\n",
      "é ser\n",
      "42 42\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for word in document1:\n",
    "    print(word, word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estudo Estudo\n",
      "da da\n",
      "linguagem linguagem\n",
      "Python Python\n",
      "para parir\n",
      "processamento processamento\n",
      "natural natural\n",
      "de de\n",
      "linguagem linguagem\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for word in document2:\n",
    "    print(word, word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['programar', 'programar', 'programar', 'programar', 'programar']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbo_conjugado = nlp('programo programei programaram programariam programe')\n",
    "[word.lemma_ for word in verbo_conjugado]\n",
    "\"\"\"mesmo utilizando diferentes modos (indicativo, subjuntivo e imperativo) e tempos verbais, o algoritmo é capaz de \n",
    "trazer o radical. No caso, o verbo no infinitivo.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconhecimento de Entidades Nomeadas\n",
    "* __NER(Named-Entity Recognition)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magazine Luisa ORG\n",
      "Brasil LOC\n"
     ]
    }
   ],
   "source": [
    "text = \"A Magazine Luisa é uma varejista do Brasil, cujo principal diferencial são os e-commerces.\"\n",
    "document = nlp(text)\n",
    "for entity in document.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Magazine Luisa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " é uma varejista do \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brasil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", cujo principal diferencial são os e-commerces.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Customizando a visualização de acordo com a entidade\n",
    "from spacy import displacy\n",
    "displacy.render(document, style = 'ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StopWords\n",
    "* Palavras que aparecem com uma grande frequência, mas que seu significado não tem influência direta com o contexto:\n",
    "-__Exemplo:__ de, para, por, na, no, em....\n",
    "-São conectivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413\n",
      "{'sete', 'novos', 'entre', 'as', 'final', 'tarde', 'apontar', 'dezanove', 'qual', 'nem', 'posição', 'momento', 'duas', 'ir', 'fez', 'tanto', 'deverá', 'tens', 'outra', 'inicio', 'disso', 'novo', 'segundo', 'depois', 'pontos', 'num', 'pela', 'custa', 'muito', 'dão', 'sempre', 'sei', 'tua', 'uns', 'que', 'sob', 'local', 'estado', 'alguns', 'através', 'cada', 'ademais', 'vindo', 'estava', 'sistema', 'estará', 'baixo', 'vêm', 'menor', 'cá', 'numa', 'terceiro', 'vinda', 'desse', 'fomos', 'nove', 'não', 'ter', 'mil', 'bom', 'demais', 'parte', 'dessa', 'sobre', 'meus', 'estas', 'adeus', 'mesmo', 'maiorias', 'elas', 'isso', 'minhas', 'nas', 'posso', 'boa', 'naquela', 'tentar', 'lhe', 'bem', 'primeiro', 'temos', 'faço', 'tivemos', 'conselho', 'fazem', 'número', 'acerca', 'sim', 'segunda', 'das', 'três', 'porque', 'põe', 'à', 'outros', 'eventual', 'certamente', 'contudo', 'quinze', 'possível', 'aquelas', 'fazemos', 'nosso', 'ele', 'irá', 'aquilo', 'aqui', 'assim', 'mas', 'ora', 'meses', 'vários', 'dezasseis', 'apoio', 'quieta', 'ser', 'vocês', 'muitos', 'às', 'sétima', 'fostes', 'pouca', 'cima', 'mal', 'todos', 'estivestes', 'geral', 'vossa', 'ou', 'lado', 'novas', 'faz', 'pois', 'têm', 'você', 'somos', 'devem', 'nenhuma', 'coisa', 'tempo', 'ponto', 'nos', 'ali', 'quer', 'conhecida', 'estão', 'nível', 'lá', 'uma', 'me', 'tal', 'seria', 'eu', 'parece', 'tenho', 'sua', 'dos', 'sois', 'números', 'suas', 'agora', 'direita', 'tais', 'comprida', 'porém', 'umas', 'esta', 'para', 'quê', 'um', 'vos', 'ambos', 'vós', 'logo', 'quieto', 'foste', 'falta', 'nessa', 'são', 'algo', 'dizer', 'porquanto', 'aos', 'talvez', 'perto', 'toda', 'saber', 'doze', 'oitava', 'vez', 'relação', 'pôde', 'atrás', 'usar', 'pelas', 'tentei', 'sou', 'nada', 'ambas', 'seus', 'se', 'por', 'nós', 'antes', 'te', 'inclusive', 'no', 'onze', 'dezassete', 'diante', 'grandes', 'fazes', 'estes', 'deste', 'cedo', 'área', 'só', 'fazia', 'vem', 'daquela', 'des', 'veja', 'ver', 'obrigada', 'fim', 'tuas', 'último', 'podem', 'qualquer', 'fazer', 'nesse', 'da', 'sétimo', 'dentro', 'nesta', 'pelo', 'teve', 'somente', 'possivelmente', 'aquela', 'bastante', 'sexta', 'dizem', 'é', 'foi', 'vais', 'pode', 'meio', 'obrigado', 'treze', 'está', 'poder', 'vão', 'tentaram', 'ao', 'tanta', 'daquele', 'aqueles', 'meu', 'foram', 'oitavo', 'estou', 'já', 'tipo', 'iniciar', 'fui', 'dez', 'quinto', 'essas', 'este', 'mês', 'vossas', 'põem', 'nuns', 'forma', 'menos', 'tu', 'quanto', 'grande', 'quarto', 'favor', 'algumas', 'quais', 'quatro', 'todo', 'deve', 'portanto', 'com', 'tivestes', 'seu', 'terceira', 'quem', 'nossas', 'após', 'apoia', 'desta', 'corrente', 'além', 'aí', 'poderá', 'estar', 'isto', 'outras', 'desde', 'naquele', 'tudo', 'vinte', 'de', 'embora', 'pelos', 'és', 'seis', 'diz', 'cuja', 'ontem', 'enquanto', 'nova', 'questão', 'teu', 'quarta', 'minha', 'debaixo', 'nunca', 'até', 'tive', 'sem', 'os', 'comprido', 'então', 'sabe', 'em', 'tiveste', 'conhecido', 'caminho', 'tem', 'nossa', 'valor', 'apenas', 'puderam', 'estive', 'máximo', 'todas', 'primeira', 'estivemos', 'ela', 'como', 'podia', 'maior', 'partir', 'nossos', 'do', 'estiveram', 'tiveram', 'oito', 'aquele', 'porquê', 'dezoito', 'próprio', 'próxima', 'cinco', 'pegar', 'esses', 'estás', 'dá', 'vens', 'grupo', 'era', 'sexto', 'vosso', 'for', 'longe', 'mais', 'na', 'neste', 'fará', 'vossos', 'tendes', 'vezes', 'breve', 'quinta', 'teus', 'vai', 'zero', 'ligado', 'esteve', 'fazeis', 'eles', 'próximo', 'essa', 'ainda', 'contra', 'quero', 'querem', 'também', 'tente', 'usa', 'esse', 'pouco', 'fora', 'tão', 'estiveste', 'cujo', 'certeza', 'povo', 'cento', 'catorze', 'lugar', 'dar', 'quando', 'dois', 'exemplo', 'onde', 'maioria'}\n"
     ]
    }
   ],
   "source": [
    "#exebindo as stopwords da língua portuguesa:\n",
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "conectivos = STOP_WORDS\n",
    "print(len(conectivos))\n",
    "print(conectivos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As stopwords são palavras que devem ser retiradas da frase durante o pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, True, True, True, True, True]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#para verificar se a palavra é uma stopword:\n",
    "\"\"\"nlp.vocab['ir'].is_stop\"\"\"\n",
    "[nlp.vocab[word].is_stop for word in conectivos][:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
